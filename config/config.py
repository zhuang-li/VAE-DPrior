import os

import torch
import json

dir_prefix = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))), 'dataset')
tarced_dir = os.path.join(dir_prefix , 'tacred/tacred_prune/')
fewrel_dir = os.path.join(dir_prefix , 'fewrel/fewrel_emar/')
webred_dir = os.path.join(dir_prefix , 'webred/')

clinc_dir = os.path.join(dir_prefix , 'clinc150/CLINC150_emar/')

person_dir = os.path.join(dir_prefix , 'personality_caption/sub_split/')

empathetic_dir = os.path.join(dir_prefix , 'empathetic_aug/')

goemotion_dir = os.path.join(dir_prefix , 'goemotion/')


glove_path = os.path.join(dir_prefix , 'glove/glove.6B.300d.txt')

prefix_dir_prefix = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))), 'PrefixTuning')

CONFIG_FEWREL = {
    'data_type':'fewrel',
    'learning_rate': 0.001,  # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'bert': 'prajjwal1/bert-small',
    'batch_size': 50,
'cache_path':'/data/saved_models/lambda_model/fewrel',
    'gradient_accumulation_steps': 1,
    'num_clusters': 10,
    'encoder': 'bilstm',  # bilstm bert
    'epoch': 2,
    'random_seed': 100,
    'aug': 'prefix',
     'few_shot_sample_number':10,
    'few_shot_num': 0,
    'task_memory_size': 200,
    'loss_margin': 0.5,
    'sequence_times': 5,
    'initial_task': 5,
    'lambda': 100,
    'aug_num_per_class': 50,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix': dir_prefix,
    'dir': fewrel_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': fewrel_dir + 'relation_name.txt',
    'training_file': fewrel_dir + 'train.txt',
    'test_file': fewrel_dir + 'test.txt',
    'valid_file': fewrel_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers': 4,
    'max_grad_norm': 1,
    'fixed': False,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "prefix_fewrel_supp",
    'prefix_task_mode': 'proto_reg',
    'vae': 'ivae',
    'topic_prior': False,
    "gpt2_model_name": "gpt2-medium",
    're_cluster': 1000,
    'reg_cluster':100,
    'aug_epoch': 34,
    'aug_iter': 1200,
    'topic_num': 1600,
    'compress_topic_num': 200,
    'debug': True,
    'topic_coeff':0.1,
    'mse_coeff':0.05,
    'gas_coeff':0.05,
    'decay':0.99,
    'epsilon':1e-5,
    'pretrain_coeff':100,
    'sample_per_class': 6,
    'classes_per_episode': 4,
    "n_support": 4,
    "max_length": 48,
    "warm_epoch": 0,
    "attention": 'dot',
    "gaussian":True,
    "style_transfer_model":'casual',
    "cuda_id":"1",
    "disentangle_loss": 3,
    "vae_type": 0,
    'intervention': 0,
    'use_quality':True,
    "activation": 'tanh',
    "is_hard_ivae": True
}




CONFIG_tarced = {
    'data_type': 'tarced',
    'learning_rate': 0.001, # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'bert': 'prajjwal1/bert-small',
    'batch_size': 50,
    'cache_path': '/data/saved_models/lambda_model/tarced',
    'gradient_accumulation_steps':1,
    'num_clusters': 10,
    'encoder': 'bilstm', # bilstm bert
    'epoch': 2,
    'random_seed': 100,
    'aug': 'eda',
    'few_shot_sample_number':10,
    'few_shot_num': 1,
    'task_memory_size': 200,
    'loss_margin': 0.5,
    "gpt2_model_name": "gpt2",
    'sequence_times': 5,
    'initial_task': 5,
    'lambda': 100,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix' : dir_prefix,
    'dir':tarced_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': tarced_dir + 'relation_name.txt',
    'training_file': tarced_dir + 'train.txt',
    'test_file': tarced_dir + 'test.txt',
    'valid_file': tarced_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers':1,
    'max_grad_norm':1,
    'fixed': False,
    'aug_num_per_class':50,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "tarced_model_gas_param_2",
    'prefix_task_mode' : 'proto_reg',
    'vae': 'ivae',
    'topic_prior': False,
    're_cluster': 1000,
    'reg_cluster': 100,
    'aug_epoch':120,
    'aug_iter': 667,
    'topic_num': 800,
    'compress_topic_num': 200,
    'debug': True,
    'topic_coeff':0.1,
    'mse_coeff':0.05,
    'gas_coeff':0.05,
    'decay':0.99,
    'epsilon':1e-5,
    'pretrain_coeff':60,
    'sample_per_class': 3,
    'classes_per_episode': 4,
    "n_support": 4,
    "max_length": 64,
    "warm_epoch": 5,
    "attention": 'dot',
    "gaussian":True,
    "style_transfer_model":'casual',
    "cuda_id":"1",
    "disentangle_loss": 1,
    "vae_type": 0,
    'intervention': 0,
    "activation": 'tanh',
    "tuning_mode": "bothtune",
    "is_hard_ivae":True,
    "var": 0
}


CONFIG_caption = {
    'data_type': 'caption',
    'learning_rate': 0.001, # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'bert': 'prajjwal1/bert-small',
    'batch_size': 50,
    'aug_num_per_class': 50,
    'cache_path': '/data/saved_models/lambda_model/caption/',
    'gradient_accumulation_steps':1,
    'num_clusters': 10,
    'encoder': 'bilstm', # bilstm bert
    'epoch': 2,
    'random_seed': 100,
    'aug': 'none',
    'few_shot_sample_number': 20,
    'few_shot_num': 0,
    "gpt2_model_name": "gpt2-medium",
    'task_memory_size': 200,
    'loss_margin': 0.5,
    'sequence_times': 5,
    'initial_task': 5,
    'lambda': 100,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix' : dir_prefix,
    'dir':person_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': person_dir + 'relation_name.txt',
    'training_file': person_dir + 'train.txt',
    'test_file': person_dir + 'test.txt',
    'valid_file': person_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers':4,
    'max_grad_norm':1,
    'fixed': False,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "caption",
    'prefix_task_mode' : 'proto_reg',
    'vae': 'ivae',
    'topic_prior': False,
    're_cluster': 1000,
    'reg_cluster': 100,
    'aug_epoch':120,
    'aug_iter': 650,
    'topic_num': 3200,
    'compress_topic_num': 200,
    'debug': True,
    'topic_coeff':1,
    'mse_coeff':1,
    'decay':0.99,
    'epsilon':1e-5,
    'pretrain_coeff':0,
    'sample_per_class' :8,
    'classes_per_episode':4,
    "n_support":4,
    "max_length":32,
    'gas_coeff': 0.05,
    "warm_epoch":5,
    "attention": 'dot',
    'intervention':0,
    "disentangle_loss":3,
    "gaussian": True,
    "style_transfer_model": 'casual',
    "activation": 'tanh',
    "is_hard_ivae":True
}


CONFIG_empathetic = {
    'data_type': 'empathetic',
    'learning_rate': 0.001, # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'batch_size': 50,
    "gpt2_model_name": "gpt2-medium",
    'aug_num_per_class': 50,
    'cache_path': '/data/saved_models/lambda_model/empathetic/',
    'gradient_accumulation_steps':1,
    'num_clusters': 10,
    'bert':'prajjwal1/bert-small',
    'encoder': 'bilstm', # bilstm bert
    'epoch': 2,
    'random_seed': 100,
    'aug': 'none',
    'few_shot_sample_number': 20,
    'few_shot_num': 0,
    'task_memory_size': 200,
    'loss_margin': 0.5,
    'sequence_times': 5,
    'initial_task': 5,
    'lambda': 100,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix' : dir_prefix,
    'dir':empathetic_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': empathetic_dir + 'relation_name.txt',
    'training_file': empathetic_dir + 'train.txt',
    'test_file': empathetic_dir + 'test.txt',
    'valid_file': empathetic_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers':1,
    'max_grad_norm':1,
    'fixed': False,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "empathetic_model_gas_param_2",
    'prefix_task_mode' : 'proto_reg',
    'vae': 'ivae',
    'topic_prior': False,
    're_cluster': 1000,
    'reg_cluster': 100,
    'aug_epoch':120,
    'aug_iter': 300,
    'topic_num': 1600,
    'compress_topic_num': 200,
    'debug': True,
    'topic_coeff':0.1,
    'mse_coeff':0.05,
    'decay':0.99,
    'epsilon':1e-5,
    'pretrain_coeff':60,
    'sample_per_class' :6,
    'classes_per_episode':4,
    "n_support":4,
    "max_length":48,
    "warm_epoch":5,
    'gas_coeff': 0.05,
    "attention": 'dot',
    "gaussian": True,
    'intervention':0,
    "disentangle_loss":0,
    "vae_type": 0,
    "tuning_mode": "bothtune",
    "style_transfer_model": 'casual',
    "activation": 'tanh',
    "is_hard_ivae":True,
    "var":0
}


CONFIG_goemotion = {
    'data_type': 'goemotion',
    'learning_rate': 0.001, # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'batch_size': 50,
    "gpt2_model_name": "gpt2-medium",
    'aug_num_per_class': 50,
    'cache_path': 'saved_models/lambda_model/goemotion/',
    'gradient_accumulation_steps':1,
    'num_clusters': 10,
    'encoder': 'bilstm', # bilstm bert
    'epoch': 2,
    'random_seed': 100,
    'aug': 'none',
    'few_shot_sample_number': 20,
    'few_shot_num': 0,
    'task_memory_size': 200,
    'loss_margin': 0.5,
    'sequence_times': 5,
    'initial_task': 5,
    'lambda': 100,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix' : dir_prefix,
    'dir':goemotion_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': goemotion_dir + 'relation_name.txt',
    'training_file': goemotion_dir + 'train.txt',
    'test_file': goemotion_dir + 'test.txt',
    'valid_file': goemotion_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers':1,
    'max_grad_norm':1,
    'fixed': False,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "empathetic_model_gas_param_2",
    'prefix_task_mode' : 'proto_reg',
    'vae': 'ivae',
    'topic_prior': False,
    're_cluster': 1000,
    'reg_cluster': 100,
    'aug_epoch':160,
    'aug_iter': 900,
    'topic_num': 3200,
    'compress_topic_num': 200,
    'debug': True,
    'topic_coeff':0.1,
    'mse_coeff':1,
    'decay':0.99,
    'epsilon':1e-5,
    'pretrain_coeff':80,
    'sample_per_class' :16,
    'classes_per_episode':6,
    "n_support":4,
    "max_length":30,
    "warm_epoch":5,
    'gas_coeff': 0.05,
    "attention": 'dot',
    "gaussian": True,
    'intervention':0,
    "disentangle_loss":0,
    "vae_type": 0,
    "style_transfer_model": 'casual',
    "activation": 'tanh',
    "is_hard_ivae": True
}



CONFIG_WEBRED = {
    'learning_rate': 0.001,  # 0.001
    'embedding_dim': 300,
    'hidden_size': 200,
    'batch_size': 50,
    'gradient_accumulation_steps': 1,
    'num_clusters': 10,
    'encoder': 'bilstm',  # bilstm bert
    'epoch': 2,
    "gpt2_model_name": "gpt2-medium",
    'random_seed': 100,
    'aug': 'none',
    'few_shot_num': 5,
    'task_memory_size': 200,
    'loss_margin': 0.5,
    'sequence_times': 5,
    'initial_task': 5,
    'topic_num': 800,
    'lambda': 100,
    'num_cands': 10,
    'num_steps': 1,
    'dir_prefix': dir_prefix,
    'dir': webred_dir,
    'vector_size': 60,
    'vector_learning_rate': 0.001,
    'epoch_base_vector': 1,
    'num_constrain': 10,
    'data_per_constrain': 5,
    'lr_alignment_model': 0.0001,
    'epoch_alignment_model': 20,
    'checkpoint_path': 'checkpoint',
    'use_gpu': True,
    'relation_file': webred_dir + 'relation_name.txt',
    'training_file': webred_dir + 'train.txt',
    'test_file': webred_dir + 'test.txt',
    'valid_file': webred_dir + 'valid.txt',
    'glove_file': glove_path,
    'task_name': 'FewRel',
    'num_workers': 4,
    'max_grad_norm': 1,
    'fixed': False,
    'prefix_dir': prefix_dir_prefix,
    'prefix_model_name': "prefix_topic_recluster_fewrel",
    'prefix_task_mode': 'proto_reg',
    'vae': True,
    'topic_prior': False,
    're_cluster': 11000,
    "activation": 'tanh',
    "is_hard_ivae": True
}



