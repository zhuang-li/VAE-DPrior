{
    "data_type": "politeness",
    "learning_rate": 0.001,
    "batch_size": 50,
    "cache_path": "lambda_model/",
    "gradient_accumulation_steps":1,
    "num_clusters": 10,
    "use_gpu": true,
    "bert": "prajjwal1/bert-small",
    "prefix_dir": "../../PrefixTuning",
    "prefix_model_name": "politeness_pretrain_3200_topics_150_epoch",
    "seen_result_file":"../../dataset/politeness/results/politeness/seen_test/",
    "unseen_result_file": "../../dataset/politeness/results/politeness/unseen_test/",
    "prefix_task_mode": "proto_reg",
    "vae": "ivae",
    "label_name": "../../dataset/politeness/label_names.txt",
    "data_dir": "../../dataset/politeness/",
    "prefixModel_name_or_path": "saved_models/prefix_model/politeness/politeness_pretrain_3200_topics_150_epoch/",
    
    "topic_prior": false,
    "aug_epoch":0,
    "is_finetune": true,
    "aug_iter": 600,
    "topic_coeff":0.1,
    "mse_coeff":1,
    "decay":0.99,
    "epsilon":1e-5,
    "pretrain_coeff":4,
    "sample_per_class": 8,
    "classes_per_episode": 4,
    "n_support": 4,
    "max_length": 128,
    "warm_epoch": 40,
    "re_cluster": 1000,
    "reg_cluster": 100,
    "attention": "dot",
    "topic_num": 3200,
    "preseqlen": 100,
    "style_transfer_model":"casual",
    "tuning_mode": "prefixtune",
    "gpt2_model_name": "gpt2",
    "disentangle_loss":3,
    "intervention":false,
    "gaussian":true,
    "activation": "tanh",
    "is_hard_ivae":false
}